{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd66534-904f-4d34-8915-33464d7f9fc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4818dd46-57c9-4cc2-bd54-fecd9cebbb47",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType, DateType, DecimalType\n",
    "from pyspark.sql.functions import col, when, sum, avg, row_number\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71ca4572-ea3e-46e9-98d7-864da51767c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"IPL Data Analysis using Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11e96f1-8707-465c-838d-c925b2119871",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2a0273-85ed-469c-a567-cad8ff87c062",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_schema = StructType([ StructField(\"match_id\", IntegerType(), nullable=True), StructField(\"over_id\", IntegerType(), nullable=True), StructField(\"ball_id\", IntegerType(), nullable=True), StructField(\"innings_no\", IntegerType(), nullable=True), StructField(\"team_batting\", StringType(), nullable=True), StructField(\"team_bowling\", StringType(), nullable=True), StructField(\"striker_batting_position\", IntegerType(), nullable=True), StructField(\"extra_type\", StringType(), nullable=True), StructField(\"runs_scored\", IntegerType(), nullable=True), StructField(\"extra_runs\", IntegerType(), nullable=True), StructField(\"wides\", IntegerType(), nullable=True), StructField(\"legbyes\", IntegerType(), nullable=True), StructField(\"byes\", IntegerType(), nullable=True), StructField(\"noballs\", IntegerType(), nullable=True), StructField(\"penalty\", IntegerType(), nullable=True), StructField(\"bowler_extras\", IntegerType(), nullable=True), StructField(\"out_type\", StringType(), nullable=True), StructField(\"caught\", BooleanType(), nullable=True), StructField(\"bowled\", BooleanType(), nullable=True), StructField(\"run_out\", BooleanType(), nullable=True), StructField(\"lbw\", BooleanType(), nullable=True), StructField(\"retired_hurt\", BooleanType(), nullable=True), StructField(\"stumped\", BooleanType(), nullable=True), StructField(\"caught_and_bowled\", BooleanType(), nullable=True), StructField(\"hit_wicket\", BooleanType(), nullable=True), StructField(\"obstructingfeild\", BooleanType(), nullable=True), StructField(\"bowler_wicket\", BooleanType(), nullable=True), StructField(\"match_date\", DateType(), nullable=True), StructField(\"season\", IntegerType(), nullable=True), StructField(\"striker\", IntegerType(), nullable=True), StructField(\"non_striker\", IntegerType(), nullable=True), StructField(\"bowler\", IntegerType(), nullable=True), StructField(\"player_out\", IntegerType(), nullable=True), StructField(\"fielders\", IntegerType(), nullable=True), StructField(\"striker_match_sk\", IntegerType(), nullable=True), StructField(\"strikersk\", IntegerType(), nullable=True), StructField(\"nonstriker_match_sk\", IntegerType(), nullable=True), StructField(\"nonstriker_sk\", IntegerType(), nullable=True), StructField(\"fielder_match_sk\", IntegerType(), nullable=True), StructField(\"fielder_sk\", IntegerType(), nullable=True), StructField(\"bowler_match_sk\", IntegerType(), nullable=True), StructField(\"bowler_sk\", IntegerType(), nullable=True), StructField(\"playerout_match_sk\", IntegerType(), nullable=True), StructField(\"battingteam_sk\", IntegerType(), nullable=True), StructField(\"bowlingteam_sk\", IntegerType(), nullable=True), StructField(\"keeper_catch\", BooleanType(), nullable=True), StructField(\"player_out_sk\", IntegerType(), nullable=True), StructField(\"matchdatesk\", DateType(), nullable=True) ])\n",
    "\n",
    "print(ball_by_ball_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f3e9e3-b69e-4db4-b555-aa8fe6389991",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df = spark.read.schema(ball_by_ball_schema).format(\"csv\").option(\"header\", \"true\").load(\"s3://ipl-data-analysis-project/Ball_By_Ball.csv\")\n",
    "\n",
    "ball_by_ball_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1678ee63-f60b-484c-b3d7-5291f8f97dc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "match_schema = StructType([\n",
    "    StructField(\"match_sk\", IntegerType(), nullable=True),\n",
    "    StructField(\"match_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"team1\", StringType(), nullable=True),\n",
    "    StructField(\"team2\", StringType(), nullable=True),\n",
    "    StructField(\"match_date\", DateType(), nullable=True),\n",
    "    StructField(\"season_year\", IntegerType(), nullable=True),\n",
    "    StructField(\"venue_name\", StringType(), nullable=True),\n",
    "    StructField(\"city_name\", StringType(), nullable=True),\n",
    "    StructField(\"country_name\", StringType(), nullable=True),\n",
    "    StructField(\"toss_winner\", StringType(), nullable=True),\n",
    "    StructField(\"match_winner\", StringType(), nullable=True),\n",
    "    StructField(\"toss_name\", StringType(), nullable=True),\n",
    "    StructField(\"win_type\", StringType(), nullable=True),\n",
    "    StructField(\"outcome_type\", StringType(), nullable=True),\n",
    "    StructField(\"manofmatch\", StringType(), nullable=True),\n",
    "    StructField(\"win_margin\", IntegerType(), nullable=True),\n",
    "    StructField(\"country_id\", IntegerType(), nullable=True)\n",
    "])\n",
    "\n",
    "match_df = spark.read.schema(match_schema).format(\"csv\").option(\"header\", \"true\").load(\"s3://ipl-data-analysis-project/Match.csv\")\n",
    "#match_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88b7078e-c590-4733-8544-ff22f22b8e05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_schema = player_schema = StructType([\n",
    "    StructField(\"player_sk\", IntegerType(), nullable=True),\n",
    "    StructField(\"player_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"player_name\", StringType(), nullable=True),\n",
    "    StructField(\"dob\", DateType(), nullable=True),\n",
    "    StructField(\"batting_hand\", StringType(), nullable=True),\n",
    "    StructField(\"bowling_skill\", StringType(), nullable=True),\n",
    "    StructField(\"country_name\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "player_df = spark.read.schema(player_schema).format(\"csv\").option(\"header\", \"true\").load(\"s3://ipl-data-analysis-project/Player.csv\")\n",
    "\n",
    "#player_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e3b9a8-b394-4a04-aba4-55d6ec6bee55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "player_match_schema = StructType([\n",
    "    StructField(\"player_match_sk\", IntegerType(), nullable=True),\n",
    "    StructField(\"playermatch_key\", DecimalType(10, 2), nullable=True),\n",
    "    StructField(\"match_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"player_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"player_name\", StringType(), nullable=True),\n",
    "    StructField(\"dob\", DateType(), nullable=True),\n",
    "    StructField(\"batting_hand\", StringType(), nullable=True),\n",
    "    StructField(\"bowling_skill\", StringType(), nullable=True),\n",
    "    StructField(\"country_name\", StringType(), nullable=True),\n",
    "    StructField(\"role_desc\", StringType(), nullable=True),\n",
    "    StructField(\"player_team\", StringType(), nullable=True),\n",
    "    StructField(\"opposit_team\", StringType(), nullable=True),\n",
    "    StructField(\"season_year\", IntegerType(), nullable=True),\n",
    "    StructField(\"is_manofthematch\", BooleanType(), nullable=True),\n",
    "    StructField(\"age_as_on_match\", IntegerType(), nullable=True),\n",
    "    StructField(\"isplayers_team_won\", BooleanType(), nullable=True),\n",
    "    StructField(\"batting_status\", StringType(), nullable=True),\n",
    "    StructField(\"bowling_status\", StringType(), nullable=True),\n",
    "    StructField(\"player_captain\", StringType(), nullable=True),\n",
    "    StructField(\"opposit_captain\", StringType(), nullable=True),\n",
    "    StructField(\"player_keeper\", StringType(), nullable=True),\n",
    "    StructField(\"opposit_keeper\", StringType(), nullable=True)\n",
    "])\n",
    "\n",
    "player_match_df = spark.read.schema(player_match_schema).format(\"csv\").option(\"header\", \"true\").load(\"s3://ipl-data-analysis-project/Player_match.csv\")\n",
    "\n",
    "#player_match_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffcded50-6f1b-4bbf-a6ae-77755df90a96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " team_schema = StructType([\n",
    "    StructField(\"team_sk\", IntegerType(), nullable=True),\n",
    "    StructField(\"team_id\", IntegerType(), nullable=True),\n",
    "    StructField(\"team_name\", StringType(), nullable=True)\n",
    "])\n",
    " \n",
    "team_df = spark.read.schema(team_schema).format(\"csv\").option(\"header\", \"true\").load(\"s3://ipl-data-analysis-project/Team.csv\")\n",
    "\n",
    "#team_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "874331bc-0600-4458-ba04-d9968c0a5b09",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter to include only valid deliveries (excluding extras like wides and no balls for specific analyses)\n",
    "ball_by_ball_df = ball_by_ball_df.filter((col(\"wides\") == 0) & (col(\"noballs\") == 0) )\n",
    "\n",
    "# Aggregation: Calculate the total and average runs scored in each match and inning\n",
    "total_and_avg_runs = ball_by_ball_df.groupBy(\"match_id\", \"innings_no\").agg(\n",
    "    sum(\"runs_scored\").alias(\"total_runs\"),\n",
    "    avg(\"runs_scored\").alias(\"average_runs\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dbef71e-6179-4c81-ac1f-db98d770c60c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Window Function: Calculate running total of runs in each match for each over\n",
    "\n",
    "WindowSpec = Window.partitionBy(\"match_id\", \"innings_no\").orderBy(\"over_id\")\n",
    "\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\"running_total_runs\", sum(\"runs_scored\").over(WindowSpec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9cca185e-1b48-4b3a-b0d5-31fbaa575d08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b8576c4-286d-4e09-b3df-c5c94311964b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Conditional Column: Flag for high impact balls (either a wicket or more than 6 runs including extras)\n",
    "ball_by_ball_df = ball_by_ball_df.withColumn(\n",
    "    \"high_impact\", when((col(\"runs_scored\") + col(\"extra_runs\") > 6) | (col(\"bowler_wicket\") == True), True).otherwise(False)\n",
    ")\n",
    "#ball_by_ball_df.show(2)\n",
    "ball_by_ball_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "616140d8-cb9c-4263-bb4d-5fe3b1367389",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, when\n",
    "\n",
    "# Extracting year, month, and day from the match date for more detailed time-based analysis\n",
    "match_df = match_df.withColumn(\"year\", year(\"match_date\"))\n",
    "match_df = match_df.withColumn(\"month\", month(\"match_date\"))\n",
    "match_df = match_df.withColumn(\"dayofmonth\", dayofmonth(\"match_date\"))\n",
    "\n",
    "# High margin win: categorizing win margins into 'high', 'medium', and 'low'\n",
    "match_df = match_df.withColumn(\n",
    "    \"win_margin_category\",\n",
    "    when(col(\"win_margin\") >= 100, \"high\")\n",
    "    .when((col(\"win_margin\") >=  50) & (col(\"win_margin\") < 100), \"medium\")\n",
    "    .otherwise(\"low\")\n",
    ")\n",
    "\n",
    "# Analyze the impact of the toss: who wins the toss and the match\n",
    "match_df = match_df.withColumn(\n",
    "    \"toss_match_winner\",\n",
    "    when(col(\"toss_winner\") == col(\"match_winner\"), \"Yes\").otherwise(\"No\")\n",
    ")\n",
    "\n",
    "# Show the enhanced match DataFrame\n",
    "match_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "861d14ec-4124-421b-a285-a2e442ce6746",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, regexp_replace\n",
    "\n",
    "\n",
    "# Normalize and clean player names\n",
    "player_df = player_df.withColumn(\"player_name\", lower(regexp_replace(\"player_name\", \"[^a-zA-Z0-9 ]\", \"\")))\n",
    "#player_df.show(10)\n",
    "\n",
    "# Handle missing values in 'batting_hand' and 'bowling_skill' with a default 'unknown'\n",
    "player_df = player_df.na.fill({\"batting_hand\": \"unknown\", \"bowling_skill\": \"unknown\"})\n",
    "\n",
    "player_df.show(10)\n",
    "\n",
    "# Categorizing players based on batting hand\n",
    "player_df = player_df.withColumn(\n",
    "    \"batting_style\",\n",
    "    when(col(\"batting_hand\").contains(\"Left\"), \"Left-Handed\").otherwise(\"Right-Handed\")\n",
    ")\n",
    "#player_df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4309f63-44f2-4f33-b6eb-d8089208d1b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, current_date, expr\n",
    "\n",
    "# Add a 'veteran_status' column based on player age\n",
    "\n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"veteran_status\",\n",
    "    when(col(\"age_as_on_match\") >= 35, \"Veteran\").otherwise(\"Non-Veteran\")\n",
    ")\n",
    "\n",
    "# Dynamic column to calculate years since debut\n",
    "\n",
    "player_match_df = player_match_df.withColumn(\n",
    "    \"years_since_debut\",\n",
    "    (year(current_date()) - col(\"season_year\"))\n",
    ")\n",
    "\n",
    "player_match_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c91ff0a4-cc17-403c-84ea-7694bbf97446",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df.createOrReplaceTempView(\"ball_by_ball\")\n",
    "match_df.createOrReplaceTempView(\"match\")\n",
    "player_df.createOrReplaceTempView(\"player\")\n",
    "player_match_df.createOrReplaceTempView(\"player_match\")\n",
    "team_df.createOrReplaceTempView(\"team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "05e6e60a-d682-496d-9e2b-a4fbedd0f185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ball_by_ball_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ca4052-8265-422d-be89-c162b9823fac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_scoring_batsman_per_season = spark.sql(\"\"\"\n",
    "select p.player_name, m.season_year,\n",
    "sum(b.runs_scored) as total_runs\n",
    "from ball_by_ball b join\n",
    "match m on b.match_id = m.match_id join \n",
    "player_match pm on m.match_id = pm.match_id and b.striker = pm.player_id\n",
    "join player p on p.player_id = pm.player_id\n",
    "group by p.player_name, m.season_year\n",
    "order by m.season_year, total_runs desc\n",
    "\"\"\")\n",
    "top_scoring_batsman_per_season.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf5a79ad-b94d-4083-8b74-bd154065d9da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "economical_bowlers_powerplay = spark.sql(\"\"\"\n",
    "select p.player_name,\n",
    "avg(b.runs_scored) as avg_runs_per_ball,\n",
    "count(b.bowler_wicket) as total_wickets\n",
    "from ball_by_ball b join player_match pm \n",
    "on pm.match_id = b.match_id and b.bowler = pm.player_id\n",
    "join player p on p.player_id = pm.player_id\n",
    "where b.over_id <= 6 group by p.player_name\n",
    "having count(*)>= 1\n",
    "order by avg_runs_per_ball, total_wickets desc                                    \n",
    "\"\"\")\n",
    "economical_bowlers_powerplay.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d37f0ed-9a95-440f-83fc-7fde183bbbc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "toss_impact_individual_matches = spark.sql(\"\"\"\n",
    "select match_id, toss_winner, toss_name, match_winner,\n",
    "case when toss_winner == match_winner then \"Won\"\n",
    "    else \"Lost\"\n",
    "end as match_outcome\n",
    "from match  where toss_name is not null\n",
    "order by match_id                                           \n",
    "\"\"\")\n",
    "\n",
    "toss_impact_individual_matches.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddcc9f63-6fdd-496c-a9fd-9132f0c52c43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "average_runs_in_wins = spark.sql(\"\"\"\n",
    "select p.player_name, \n",
    "avg(b.runs_scored) as avg_runs_in_wins,\n",
    "count(*) as innings_played\n",
    "from ball_by_ball b \n",
    "join player_match pm  on b.match_id = pm.match_id and b.striker = pm.player_id\n",
    "join player p on p.player_id = pm.player_id\n",
    "join match m on pm.match_id = m.match_id\n",
    "where m.match_winner = pm.player_team\n",
    "group by p.player_name\n",
    "order by avg_runs_in_wins desc                                 \n",
    "\"\"\")\n",
    "\n",
    "average_runs_in_wins.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "237b97de-01c7-4828-85a8-fd3c85c35e70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729d6744-eea1-4da5-af97-4a356a350c53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assuming 'economical_bowlers_powerplay' is already executed and available as a Spark DataFrame\n",
    "economical_bowlers_pd = economical_bowlers_powerplay.toPandas()\n",
    "\n",
    "# Visualizing using Matplotlib\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Limiting to top 10 for clarity in the plot\n",
    "top_economical_bowlers = economical_bowlers_pd.nsmallest(20, 'avg_runs_per_ball')\n",
    "plt.bar(top_economical_bowlers['player_name'], top_economical_bowlers['avg_runs_per_ball'], color='lightgreen')\n",
    "plt.xlabel('Bowler Name')\n",
    "plt.ylabel('Average Runs per Ball')\n",
    "plt.title('Most Economical Bowlers in Powerplay Overs (Top 20)')\n",
    "plt.xticks(rotation=50)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06b16434-9595-4727-949f-09de40c0bd15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "toss_impact_pd = toss_impact_individual_matches.toPandas()\n",
    "\n",
    "\n",
    "# Creating a countplot to show win/loss after winning toss\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='toss_winner', hue='match_outcome', data=toss_impact_pd)\n",
    "plt.title('Impact of Winning Toss on Match Outcomes')\n",
    "plt.xlabel('Toss Winner')\n",
    "plt.ylabel('Number of Matches')\n",
    "plt.legend(title='Match Outcome')\n",
    "plt.xticks(rotation=50)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8088f17a-389a-4303-8498-ca383c5919dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "average_runs_pd = average_runs_in_wins.toPandas()\n",
    "# Using seaborn to plot average runs in winning matches\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_scorers = average_runs_pd.nlargest(20, 'avg_runs_in_wins')\n",
    "sns.barplot(x='player_name', y='avg_runs_in_wins', data=top_scorers)\n",
    "plt.title('Average Runs Scored by Batsmen in Winning Matches (Top 20 Scorers)')\n",
    "plt.xlabel('Player Name')\n",
    "plt.ylabel('Average Runs in Wins')\n",
    "plt.xticks(rotation=50)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b15b2df8-b5d7-427b-9047-5e9cc4cacca8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scores_by_venue = spark.sql(\"\"\"\n",
    "    select venue_name, avg(total_runs) as avg_score, max(total_runs) as highest_score\n",
    "    from ( \n",
    "        select b.match_id, m.venue_name, sum(runs_scored) as total_runs\n",
    "        from ball_by_ball b join\n",
    "        match m on b.match_id = m.match_id\n",
    "        group by b.match_id, m.venue_name\n",
    "    )\n",
    "    group by venue_name order by avg_score desc\n",
    "\"\"\")\n",
    "scores_by_venue.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10fa9502-8ae7-44cc-887f-d4e84b683c18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scores_by_venue_pd = scores_by_venue.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='avg_score', y='venue_name', data=scores_by_venue_pd)\n",
    "plt.title('Distribution of Scores by Venue')\n",
    "plt.xlabel('Average Score')\n",
    "plt.ylabel('Venue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "174345a1-bb5e-4069-9b33-8e0199649ca2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dismissal_types = spark.sql(\"\"\"\n",
    "select out_type, count(*) as frequency from ball_by_ball\n",
    "where out_type is not null \n",
    "group by out_type\n",
    "order by frequency desc                            \n",
    "\"\"\")\n",
    "\n",
    "dismissal_types.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaab5fb4-1683-423e-bf1c-f61ef8db41f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dismissal_types_pd = dismissal_types.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='out_type', y='frequency', data=dismissal_types_pd, palette='pastel')\n",
    "plt.title('Most Frequent Dismissal Types')\n",
    "plt.xlabel('Dismissal Type')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc3cd605-4ff7-4744-83fa-454467f7593d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "team_toss_win_performance = spark.sql(\"\"\"\n",
    "select team1, count(*) as matches_played,\n",
    "sum(case when toss_winner == match_winner then 1 else 0 end) as wins_after_toss\n",
    "from match\n",
    "where toss_winner = team1 \n",
    "group by team1 \n",
    "order by wins_after_toss desc\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "team_toss_win_performance.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "070256dc-ce84-497d-bf24-81edac10d7ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "team_toss_win_pd = team_toss_win_performance.toPandas()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='team1', y='wins_after_toss', data=team_toss_win_pd)\n",
    "plt.title('Team Performance After Winning Toss')\n",
    "plt.xlabel('Team')\n",
    "plt.ylabel('Wins After Winning Toss')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41a34125-402a-46bf-8dfa-e9ef821078db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "IPL-Data-Analysis-Spark-NB",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
